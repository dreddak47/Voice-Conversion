{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnDUFmKsih2e"
      },
      "source": [
        "#**VOICE CONVERSION (ML PROJECT PHASE 2) - GROUP 30 - PART_2 - FINAL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffc1yDz2ircF"
      },
      "source": [
        "##**SETTING UP THE SYSTEM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oWMoUf8aksSf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_52I997irgJ"
      },
      "source": [
        "##**GETTING THE AUDIO FILES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "founZgmlkr5k",
        "outputId": "ab12d662-d057-4171-ebf2-dea0ef628df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting the drive and getting the data\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aphABqTLnS5V"
      },
      "outputs": [],
      "source": [
        "!pip install pysptk pyworld librosa tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR-M9a9uqr-j"
      },
      "outputs": [],
      "source": [
        "!pip install nnmnkwii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvVr1NZaqGNs"
      },
      "outputs": [],
      "source": [
        "from os.path import join, expanduser\n",
        "DIRECTORY = join(expanduser(\"~\"), \"/content/drive/MyDrive/ML_PROJECT/PHASE_2/\", \"Audio_Testing\")\n",
        "!ls $DIRECTORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk7jo21xqjcA"
      },
      "outputs": [],
      "source": [
        "%pylab inline\n",
        "rcParams[\"figure.figsize\"] = (16,5)\n",
        "\n",
        "from nnmnkwii.datasets import PaddedFileSourceDataset as padding\n",
        "from nnmnkwii.preprocessing.alignment import DTWAligner as dtw\n",
        "from nnmnkwii.preprocessing import trim_zeros_frames as trim_frames\n",
        "from nnmnkwii.preprocessing import remove_zeros_frames as remove_frames\n",
        "from nnmnkwii.preprocessing import delta_features as first_der\n",
        "from nnmnkwii.util import apply_each2d_trim as trim_2d\n",
        "from nnmnkwii.metrics import melcd as mel_CD\n",
        "from nnmnkwii.baseline.gmm import MLPG\n",
        "from nnmnkwii.datasets import FileDataSource\n",
        "from nnmnkwii.datasets.cmu_arctic import CMUArcticWavFileDataSource\n",
        "\n",
        "from os.path import basename, splitext\n",
        "from os import listdir\n",
        "from os.path import isdir, join, splitext\n",
        "\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pyworld\n",
        "import pysptk\n",
        "from pysptk.synthesis import MLSADF, Synthesizer\n",
        "import IPython\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q-jh1dXes4ii"
      },
      "outputs": [],
      "source": [
        "sampling_rate = 48000\n",
        "alpha_val = pysptk.util.mcepalpha(sampling_rate)\n",
        "n_mcc = 30\n",
        "frame_quantum = 5\n",
        "hopsize = int(sampling_rate * (frame_quantum * 0.001))\n",
        "fft_len=pyworld.get_cheaptrick_fft_size(sampling_rate)\n",
        "windows = [\n",
        "    (0, 0, np.array([1.0])),\n",
        "    (1, 1, np.array([-0.5, 0.0, 0.5])),\n",
        "    (1, 1, np.array([1.0, -2.0, 1.0])),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "801V1Y9Gjxvt"
      },
      "outputs": [],
      "source": [
        "# Make sure to add the speaker folders with wav files in the defined directory\n",
        "available_speakers= ['c1' ,'c2','c3','c4','c5','c6']\n",
        "\n",
        "def _name_to_dirname(name):\n",
        "    # assert len(name) == 3\n",
        "    return join(\"{}\".format(name), \"wav\")\n",
        "\n",
        "# Reference to the below class: https://r9y9.github.io/nnmnkwii/latest/_modules/nnmnkwii/datasets/cmu_arctic.html\n",
        "class WavFileDataSource(FileDataSource):\n",
        "    def _init_(self, data_root, speakers, labelmap=None, max_files=None):\n",
        "        for speaker in speakers:\n",
        "            if speaker not in available_speakers:\n",
        "                raise ValueError(\n",
        "                    \"Unknown speaker '{}'. It should be one of {}\".format(\n",
        "                        speaker, available_speakers\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        self.data_root = data_root\n",
        "        self.speakers = speakers\n",
        "        if labelmap is None:\n",
        "            labelmap = {}\n",
        "            for idx, speaker in enumerate(speakers):\n",
        "                labelmap[speaker] = idx\n",
        "        self.labelmap = labelmap\n",
        "        self.max_files = max_files\n",
        "        self.labels = None\n",
        "\n",
        "    def collect_files(self):\n",
        "        \"\"\"Collect wav files for specific speakers.\n",
        "\n",
        "        Returns:\n",
        "            list: List of collected wav files.\n",
        "        \"\"\"\n",
        "        speaker_dirs = list(\n",
        "            map(lambda i: join(self.data_root, _name_to_dirname(i)), self.speakers)\n",
        "        )\n",
        "        print(speaker_dirs)\n",
        "        paths = []\n",
        "        labels = []\n",
        "\n",
        "        if self.max_files is None:\n",
        "            max_files_per_speaker = None\n",
        "        else:\n",
        "            max_files_per_speaker = self.max_files // len(self.speakers)\n",
        "        for (i, d) in enumerate(speaker_dirs):\n",
        "            if not isdir(d):\n",
        "                raise RuntimeError(\"{} doesn't exist.\".format(d))\n",
        "            files = [join(speaker_dirs[i], f) for f in listdir(d)]\n",
        "            files = list(filter(lambda i: splitext(i)[1] == \".wav\", files))\n",
        "            files = sorted(files)\n",
        "            files = files[:max_files_per_speaker]\n",
        "            for f in files:\n",
        "                paths.append(f)\n",
        "                labels.append(self.labelmap[self.speakers[i]])\n",
        "\n",
        "        self.labels = np.array(labels, dtype=np.int32)\n",
        "        return paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VDT4RGPAs73O"
      },
      "outputs": [],
      "source": [
        "class MyFileDataSource(WavFileDataSource):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MyFileDataSource, self).__init__(*args, **kwargs)\n",
        "        self.test_paths = None\n",
        "\n",
        "    def collect_files(self):\n",
        "        paths = super(\n",
        "            MyFileDataSource, self).collect_files()\n",
        "        train_paths, test_paths = train_test_split(\n",
        "            paths, test_size=0.03, random_state=1234)\n",
        "        self.test_paths = test_paths\n",
        "        return train_paths\n",
        "\n",
        "    def collect_features(self, path):\n",
        "        sampling_rate, audio_data = wavfile.read(path)\n",
        "        audio_data = audio_data.astype(np.float64)\n",
        "        freq, timeaxis = pyworld.dio(audio_data, sampling_rate, frame_period=frame_quantum)\n",
        "        freq = pyworld.stonemask(audio_data, freq, timeaxis, sampling_rate)\n",
        "        spect = pyworld.cheaptrick(audio_data, freq, timeaxis, sampling_rate)\n",
        "        spect = trim_frames(spect)\n",
        "        mcc = pysptk.sp2mc(spect, order=n_mcc, alpha=alpha_val)\n",
        "        return mcc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8t1KdHbJs-Nx"
      },
      "outputs": [],
      "source": [
        "src_attr = MyFileDataSource(data_root=DIRECTORY,\n",
        "                                         speakers=[\"bdl\"], max_files=100)\n",
        "tgt_attr = MyFileDataSource(data_root=DIRECTORY,\n",
        "                                         speakers=[\"slt\"], max_files=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ds48mEbttAKV"
      },
      "outputs": [],
      "source": [
        "src = padding(src_attr, 2000).asarray()\n",
        "tgt = padding(tgt_attr, 2000).asarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oQlIYGoztEJt"
      },
      "outputs": [],
      "source": [
        "aligned_src, aligned_tgt = dtw(verbose=0, dist=mel_CD).transform((src, tgt))\n",
        "aligned_src, aligned_tgt = aligned_src[:, :, 1:], aligned_tgt[:, :, 1:]\n",
        "dim_static = aligned_src.shape[-1]\n",
        "aligned_src = trim_2d(first_der, aligned_src, windows)\n",
        "aligned_tgt = trim_2d(first_der, aligned_tgt, windows)\n",
        "combined_features = np.concatenate((aligned_src, aligned_tgt), axis=-1).reshape(-1, aligned_src.shape[-1]*2)\n",
        "combined_features = remove_frames(combined_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSI282qNtPT4"
      },
      "outputs": [],
      "source": [
        "\n",
        "gmm_model = GaussianMixture(n_components=64, covariance_type=\"full\", max_iter=100, verbose=1)\n",
        "%time gmm_model.fit(combined_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1dOasw7Mjxv4"
      },
      "outputs": [],
      "source": [
        "def features_collect(source_path):\n",
        "    sampling_rate, audio_data = wavfile.read(source_path)\n",
        "    audio_data = audio_data.astype(np.float64)\n",
        "    freq, timeaxis = pyworld.dio(audio_data, sampling_rate, frame_period=frame_quantum)\n",
        "    freq = pyworld.stonemask(audio_data, freq, timeaxis, sampling_rate)\n",
        "    spect = pyworld.cheaptrick(audio_data, freq, timeaxis, sampling_rate)\n",
        "    mcc = pysptk.sp2mc(spect, order=n_mcc, alpha=alpha_val)\n",
        "    return mcc, audio_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5R-Cmf8ytUsA"
      },
      "outputs": [],
      "source": [
        "def test(source_path, enable_mlpg=True, vc=True):\n",
        "    if enable_mlpg:\n",
        "        paramgen = MLPG(gmm_model, windows=windows, diff=vc)\n",
        "    else:\n",
        "        paramgen = MLPG(gmm_model, windows=[(0,0, np.array([1.0]))], diff=vc)\n",
        "\n",
        "    mcc, audio_data=features_collect(source_path)\n",
        "    mcc0, mcc = mcc[:, 0], mcc[:, 1:]\n",
        "    mcc = first_der(mcc, windows)\n",
        "    mcc = paramgen.transform(mcc)\n",
        "    if (not enable_mlpg) and (mcc.shape[-1] != dim_static):\n",
        "        mcc = mcc[:,:dim_static]\n",
        "    assert mcc.shape[-1] == dim_static\n",
        "    mcc = np.hstack((mcc0[:, None], mcc))\n",
        "    mcc[:, 0] = 0\n",
        "    engine = Synthesizer(MLSADF(order=n_mcc, alpha=alpha_val), hopsize=hopsize)\n",
        "    b = pysptk.mc2b(mcc.astype(np.float64), alpha=alpha_val)\n",
        "    waveform = engine.synthesis(audio_data, b)\n",
        "\n",
        "    return waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAShAeCLtV5V"
      },
      "outputs": [],
      "source": [
        "for i, (src_path, tgt_path) in enumerate(zip(src_attr.test_paths, tgt_attr.test_paths)):\n",
        "    print(\"Test - {}\".format(i+1))\n",
        "    without_MLPG = test(src_path, enable_mlpg=False)\n",
        "    with_MLPG = test(src_path, enable_mlpg=True)\n",
        "    _, src = wavfile.read(src_path)\n",
        "    _, tgt = wavfile.read(tgt_path)\n",
        "\n",
        "    print(\"Source Audio:\", basename(src_path))\n",
        "    IPython.display.display(Audio(src, rate=sampling_rate))\n",
        "    print(\"Target Audio:\", basename(tgt_path))\n",
        "    IPython.display.display(Audio(tgt, rate=sampling_rate))\n",
        "    print(\"With MLPG Converted Audio:\")\n",
        "    IPython.display.display(Audio(with_MLPG, rate=sampling_rate))\n",
        "    print(\"Without MLPG Converted Audio:\")\n",
        "    IPython.display.display(Audio(without_MLPG, rate=sampling_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N89eHqjXp0lM"
      },
      "outputs": [],
      "source": [
        "from joblib import dump\n",
        "# from joblib importÂ load\n",
        "import os\n",
        "model_filename = f\"gmm_model_3.joblib\"\n",
        "model_path = os.path.join(\"/content/\", model_filename)\n",
        "dump(gmm_model, model_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ffc1yDz2ircF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
